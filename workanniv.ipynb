{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Scraping Script (works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "from linkedin_scraper import Person, actions\n",
    "from selenium import webdriver\n",
    "from parsel import Selector\n",
    "driver = webdriver.Chrome('/Users/Nick/chromedriver.exe')\n",
    "email = 'nanderson993@gmail.com'\n",
    "password = 'Nickmike93!'\n",
    "actions.login(driver, email, password)\n",
    "\n",
    "client_urls = ['https://www.linkedin.com/in/nicholas-andersonchi/', 'https://www.linkedin.com/in/benjaminsolomon/']\n",
    "response = client_urls\n",
    "\n",
    "df = pd.DataFrame(columns=['Name', 'Work Anniversary'])\n",
    "for idx, url in enumerate(client_urls):\n",
    "    driver.get(url)\n",
    "    for idk, url in enumerate(client_urls):\n",
    "        experience = driver.find_elements_by_css_selector('#experience-section .pv-profile-section')\n",
    "        for item in experience:\n",
    "            for idx2, item in enumerate(experience[0:1]):\n",
    "                df.loc[idx, 'Work Anniversary'] = item.text\n",
    "                name = response.css('title::text').get\n",
    "                for idk, url in enumerate(client_urls):\n",
    "                    for idx2, item in enumerate(name[0:1]):\n",
    "                        df.loc[idx, 'Name'] = item.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuckery Zone \n",
    "\n",
    "### Gettin' deez damn names and experrence \n",
    "\n",
    "https://docs.scrapy.org/en/latest/topics/selectors.html Selector notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "from linkedin_scraper import Person, actions\n",
    "from selenium import webdriver\n",
    "from parsel import Selector\n",
    "import jsonpickle\n",
    "\n",
    "def __init__(self, filename):\n",
    "            self.WorkAnniv = self\n",
    "\n",
    "def read_csv(filename):\n",
    "            with open(filename, newline='') as filename:\n",
    "                rd = pd.read_csv(filename, sep=',')\n",
    "            return rd\n",
    "\n",
    "        \n",
    "def li_login(filename):\n",
    "    driver = webdriver.Chrome('/path/to/chromedriver.exe')\n",
    "    email = 'yo email'\n",
    "    password = '**********'\n",
    "    action = actions.login(driver, email, password)\n",
    "    return action\n",
    "\n",
    "def client_url(filename):\n",
    "        client_urls = []\n",
    "        rd = read_csv(filename)\n",
    "        url_list = rd\n",
    "        for line in list(rd):\n",
    "            client_urls.append(url_list)\n",
    "            print(client_urls)\n",
    "        return client_urls\n",
    "\n",
    "def li_scrape_exp(filename):\n",
    "    driver = webdriver.Chrome('/Users/Nick/chromedriver.exe')\n",
    "    client_urls = client_url(filename)\n",
    "    print(client_urls)\n",
    "    df = pd.DataFrame(columns=['Name', 'Work Anniversary'])\n",
    "    for idx, url in enumerate(client_urls):\n",
    "        experience = driver.find_elements_by_css_selector('#experience-section .pv-profile-section')\n",
    "        print(experience)\n",
    "        for item in experience:\n",
    "            for idx2, item in enumerate(experience[0:1]):\n",
    "                df.loc[idx, 'Work Anniversary'] = item.text\n",
    "    return print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_login('workannivtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        https://www.linkedin.com/in/benjaminsolomon/\n",
      "0  https://www.linkedin.com/in/nicholas-andersonchi/\n",
      "1  https://www.linkedin.com/in/zach-sweeney-a378a...\n",
      "2  https://www.linkedin.com/in/adrian-jordan-comm...\n",
      "3       https://www.linkedin.com/in/shannon-n-kelly/]\n",
      "[        https://www.linkedin.com/in/benjaminsolomon/\n",
      "0  https://www.linkedin.com/in/nicholas-andersonchi/\n",
      "1  https://www.linkedin.com/in/zach-sweeney-a378a...\n",
      "2  https://www.linkedin.com/in/adrian-jordan-comm...\n",
      "3       https://www.linkedin.com/in/shannon-n-kelly/]\n",
      "[]\n",
      "Empty DataFrame\n",
      "Columns: [Name, Work Anniversary]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "li_scrape_exp('workannivtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
